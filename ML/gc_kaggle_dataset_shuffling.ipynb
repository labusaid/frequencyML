{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gc_kaggle_dataset_shuffling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJWBHe0ZgE6e"
      },
      "source": [
        "#Block used to upload kaggle.json, for access to Kaggle API\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCWe-Ofxnvc3"
      },
      "source": [
        "#block for installing kaggle, creation of kaggle dir, and copying the json file over to current dir\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g76Mh8Uqn4AQ"
      },
      "source": [
        "#Block for downloading dataset\n",
        "! kaggle datasets download pinxau1000/radioml2018"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeMhGhxppIrd"
      },
      "source": [
        "#Block for unziping downloaded file\n",
        "! unzip radioml2018.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY1VFzR9ropQ"
      },
      "source": [
        "#code block for loading in DeepSig data from hdf5 file\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import numpy as np\n",
        "import json\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "# Open the dataset\n",
        "hdf5_file = h5py.File(\"/content/GOLD_XYZ_OSC.0001_1024.hdf5\",  'r')\n",
        "# Load the modulation classes. You can also copy and paste the content of classes-fixed.txt.\n",
        "modulation_classes = json.load(open(\"/content/classes-fixed.json\", 'r'))\n",
        "#List groups of the hdf5 file\n",
        "list(hdf5_file.keys())\n",
        "\n",
        "#opening up new hdf5 file\n",
        "f_shuffle = h5py.File(\"./DeepSig_XYZ_OSC.0001_1024_Shuffled.hdf5\", \"a\")\n",
        "#creating the file groups\n",
        "x_shuf = f_shuffle.create_dataset(\"X\", (2555904,1024,2), dtype='f')\n",
        "y_shuf = f_shuffle.create_dataset(\"Y\", (2555904, 24), dtype='i')\n",
        "z_shuf = f_shuffle.create_dataset(\"Z\", (2555904,1), dtype='i')\n",
        "#creating the datasets in each group\n",
        "\n",
        "#indexes representing the quarters of the dataset\n",
        "#used to take a quarter of the original database at a time, shuffling it, and storing it into new hdf5\n",
        "qrt_one = 638976\n",
        "qrt_two = 1277952\n",
        "qrt_three = 1916928\n",
        "\n",
        "\n",
        "# Read the HDF5 groups, loading the entire group into numpy arrays\n",
        "#samples = hdf5_file['X'][:638976:]\n",
        "#modulation_onehot = hdf5_file['Y'][:638976:]\n",
        "#snr = hdf5_file['Z'][:638976:]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpoSHsQarpcx"
      },
      "source": [
        "# Read the HDF5 groups, loading a quarter of the dataset object into numpy arrays\n",
        "samples = hdf5_file['X'][:qrt_one:]\n",
        "modulation_onehot = hdf5_file['Y'][:qrt_one:]\n",
        "snr = hdf5_file['Z'][:qrt_one:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV1Ncegvrp3V"
      },
      "source": [
        "#creation of  shuffled arrays from DeepSig dataset using sklearns's shuffle function\n",
        "from sklearn.utils import shuffle\n",
        "samples, modulation_onehot, snr = shuffle(samples, modulation_onehot, snr, random_state=0)\n",
        "\n",
        "#debugging print statements\n",
        "print(samples)\n",
        "print(modulation_onehot)\n",
        "print(snr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbeksqjrrqD7"
      },
      "source": [
        "#writing to the new hdf5 dataset objects\n",
        "x_shuf[:qrt_one:] = samples[::]\n",
        "y_shuf[:qrt_one:] = modulation_onehot[::]\n",
        "z_shuf[:qrt_one:] = snr[::]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjwOXs7ZA5oV"
      },
      "source": [
        "#repeat the process for each quarter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmJ_ylcWrqKA"
      },
      "source": [
        "# Read the HDF5 groups, loading a quarter of the dataset object into numpy arrays\n",
        "samples = hdf5_file['X'][qrt_one:qrt_two:]\n",
        "modulation_onehot = hdf5_file['Y'][qrt_one:qrt_two:]\n",
        "snr = hdf5_file['Z'][qrt_one:qrt_two:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pyV-uWotDLc"
      },
      "source": [
        "#creation of  shuffled arrays from DeepSig dataset using sklearns's shuffle function\n",
        "from sklearn.utils import shuffle\n",
        "samples, modulation_onehot, snr = shuffle(samples, modulation_onehot, snr, random_state=0)\n",
        "\n",
        "print(samples)\n",
        "print(modulation_onehot)\n",
        "print(snr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i2HWDNrtDSI"
      },
      "source": [
        "#writing to the new hdf5 dataset objects\n",
        "x_shuf[qrt_one:qrt_two:] = samples[::]\n",
        "y_shuf[qrt_one:qrt_two:] = modulation_onehot[::]\n",
        "z_shuf[qrt_one:qrt_two:] = snr[::]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KKUzfmUt1m6"
      },
      "source": [
        "# Read the HDF5 groups, loading a quarter of the dataset object into numpy arrays\n",
        "samples = hdf5_file['X'][qrt_two:qrt_three:]\n",
        "modulation_onehot = hdf5_file['Y'][qrt_two:qrt_three:]\n",
        "snr = hdf5_file['Z'][qrt_two:qrt_three:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tN13Enzt1uQ"
      },
      "source": [
        "#creation of  shuffled arrays from DeepSig dataset using sklearns's shuffle function\n",
        "from sklearn.utils import shuffle\n",
        "samples, modulation_onehot, snr = shuffle(samples, modulation_onehot, snr, random_state=0)\n",
        "\n",
        "print(samples)\n",
        "print(modulation_onehot)\n",
        "print(snr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtHCuTqxt1ye"
      },
      "source": [
        "#writing to the new hdf5 dataset objects\n",
        "x_shuf[qrt_two:qrt_three:] = samples[::]\n",
        "y_shuf[qrt_two:qrt_three:] = modulation_onehot[::]\n",
        "z_shuf[qrt_two:qrt_three:] = snr[::]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU_q7RNEu7w8"
      },
      "source": [
        "# Read the HDF5 groups, loading a quarter of the dataset object into numpy arrays\n",
        "samples = hdf5_file['X'][qrt_three::]\n",
        "modulation_onehot = hdf5_file['Y'][qrt_three::]\n",
        "snr = hdf5_file['Z'][qrt_three::]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCNqMr19u718"
      },
      "source": [
        "#creation of  shuffled arrays from DeepSig dataset using sklearns's shuffle function\n",
        "from sklearn.utils import shuffle\n",
        "samples, modulation_onehot, snr = shuffle(samples, modulation_onehot, snr, random_state=0)\n",
        "\n",
        "print(samples)\n",
        "print(modulation_onehot)\n",
        "print(snr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maX0mPkIu75D"
      },
      "source": [
        "#writing to the new hdf5 dataset objects\n",
        "x_shuf[qrt_three::] = samples[::]\n",
        "y_shuf[qrt_three::] = modulation_onehot[::]\n",
        "z_shuf[qrt_three::] = snr[::]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J74688_7vu8s"
      },
      "source": [
        "#closing both files\n",
        "hdf5_file.close()\n",
        "f_shuffle.close()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-fBElaAwexL",
        "outputId": "54ac4c80-05bb-44a2-8d77-93f5ac00374b"
      },
      "source": [
        "#manually moved new hdf5 file and other dataset description files(license, classes, etc.)\n",
        "#into one folder and zip it\n",
        "!zip -r /content/DS_shuffled.zip /content/DeepSig_shuffled"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/DeepSig_shuffled/ (stored 0%)\n",
            "  adding: content/DeepSig_shuffled/datasets.desktop (deflated 19%)\n",
            "  adding: content/DeepSig_shuffled/DeepSig_XYZ_OSC.0001_1024_Shuffled.hdf5 (deflated 8%)\n",
            "  adding: content/DeepSig_shuffled/classes-fixed.json (deflated 54%)\n",
            "  adding: content/DeepSig_shuffled/LICENSE.TXT (deflated 69%)\n",
            "  adding: content/DeepSig_shuffled/classes.txt (deflated 55%)\n",
            "  adding: content/DeepSig_shuffled/classes-fixed.txt (deflated 76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_8h3Ecx0Mp0"
      },
      "source": [
        "#mounted google drive\n",
        "#move the zipped dataset file to google drive\n",
        "! mv ./DS_shuffled.zip ./drive/MyDrive "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpLwSaEJ4HcI"
      },
      "source": [
        "#flush buffer and unmount google drive\n",
        "from google.colab import drive\n",
        "drive.flush_and_unmount()"
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}
